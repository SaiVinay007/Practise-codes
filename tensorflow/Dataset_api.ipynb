{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "\n",
    "# From numpy\n",
    "\n",
    "# random vector of size 100,2\n",
    "x = np.random.sample([100,2])\n",
    "# making a dataset from a numpy array\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "\n",
    "# We can also pass more than one numpy array \n",
    "# one classic example is when we have a couple of data divided into features and labels\n",
    "features,labels = (np.random.sample([100,2]),\n",
    "                  np.random.sample([100,1]))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features,labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From tensors\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(tf.random_uniform([100,2]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From placeholders\n",
    "# This is useful when we want to dynamic change the data inside the Dataset\n",
    "\n",
    "x = tf.placeholder(tf.float32,shape=[None,2])\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[[2]\n",
      " [3]]\n",
      "[[3]\n",
      " [4]\n",
      " [5]]\n"
     ]
    }
   ],
   "source": [
    "# From generator\n",
    "# This is useful when we have an array of different elements length (e.g a sequence)\n",
    "\n",
    "sequence = np.array([[[1]],[[2],[3]],[[3],[4],[5]]])\n",
    "\n",
    "def generator():\n",
    "    for el in sequence:\n",
    "        yield el\n",
    "\n",
    "dataset = tf.data.Dataset().batch(1).from_generator(generator,\n",
    "                                           output_types= tf.int64, \n",
    "                                           output_shapes=(tf.TensorShape([None, 1])))\n",
    "\n",
    "iter = dataset.make_initializable_iterator()\n",
    "el = iter.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iter.initializer)\n",
    "    print(sess.run(el))\n",
    "    print(sess.run(el))\n",
    "    print(sess.run(el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93211826 0.88582461]\n",
      "[0.54476931 0.12532809]\n",
      "Tensor(\"IteratorGetNext_1067:0\", shape=(2,), dtype=float64)\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "# Create an iterator\n",
    "\n",
    "'''\n",
    "One shot: It can iterate once through a dataset, you cannot feed any value to it.\n",
    "\n",
    "Initializable: You can dynamically change calling its initializer operation and passing the new data with feed_dict .\n",
    "It’s basically a bucket that you can fill with stuff.\n",
    "\n",
    "Reinitializable: It can be initialised from different Dataset.\n",
    "Very useful when you have a training dataset that needs some additional transformation,\n",
    "eg. shuffle, and a testing dataset. It’s like using a tower crane to select different container.\n",
    "   \n",
    "Feedable: It can be used to select with iterator to use. \n",
    "Following the previous example, it’s like a tower crane that selects which tower crane to use to select\n",
    "which container to take.\n",
    "\n",
    "'''\n",
    "\n",
    "x = np.random.sample([100,2])\n",
    "# make dataset from numpy array\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "\n",
    "# create iterator\n",
    "\n",
    "# One shot\n",
    "iter = dataset.make_one_shot_iterator()\n",
    "\n",
    "# Then you need to call get_next() to get the tensor that will contain your data\n",
    "el = iter.get_next()\n",
    "el1 = iter.get_next()\n",
    "\n",
    "# el = []\n",
    "# for i in range(90):\n",
    "#     el.append(iter.get_next())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(el))\n",
    "    print(sess.run((el1)))\n",
    "    print(iter.get_next())\n",
    "    print(sess.run(tf.shape(el)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6401815 0.5240811]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "In case we want to build a dynamic dataset in which we can change the data source at runtime,\n",
    "we can create a dataset with a placeholder.\n",
    "Then we can initialize the placeholder using the common feed-dict mechanism.\n",
    "This is done with an initializable iterator\n",
    "'''\n",
    "\n",
    "\n",
    "# using a placeholder\n",
    "x = tf.placeholder(tf.float32, shape=[None,2])\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "\n",
    "data = np.random.sample((100,2))\n",
    "\n",
    "iter = dataset.make_initializable_iterator() # create the iterator\n",
    "el = iter.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # feed the placeholder with data\n",
    "    sess.run(iter.initializer, feed_dict={ x: data }) \n",
    "    print(sess.run(el)) # output [ 0.52374458  0.71968478]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
