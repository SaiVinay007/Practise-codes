{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Use CUDA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create Environments</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.multiprocessing_env import SubprocVecEnv\n",
    "\n",
    "num_envs = 16\n",
    "env_name = \"Pendulum-v0\"\n",
    "\n",
    "def make_env():\n",
    "    def _thunk():\n",
    "        env = gym.make(env_name)\n",
    "        return env\n",
    "\n",
    "    return _thunk\n",
    "\n",
    "envs = [make_env() for i in range(num_envs)]\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Neural Network</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, mean=0., std=0.1)\n",
    "        nn.init.constant_(m.bias, 0.1)\n",
    "#         print(\"hello\")\n",
    "#         print(m)\n",
    "        \n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, hidden_size, std=0.0):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, num_outputs),\n",
    "        )\n",
    "        self.log_std = nn.Parameter(torch.ones(1, num_outputs) * std)\n",
    "        \n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        value = self.critic(x)\n",
    "        mu    = self.actor(x)\n",
    "        std   = self.log_std.exp().expand_as(mu)\n",
    "        dist  = Normal(mu, std)\n",
    "        return dist, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActorCritic(\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=10, out_features=1, bias=True)\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=10, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([[ 0.9536, -0.3012, -0.9155],\n",
      "        [ 0.0483,  0.9988,  0.3993],\n",
      "        [ 0.4146, -0.9100, -0.6050],\n",
      "        [-0.4179, -0.9085,  0.8150],\n",
      "        [-0.3031, -0.9530,  0.7499],\n",
      "        [ 0.0602,  0.9982, -0.6320],\n",
      "        [-0.9819,  0.1893, -0.9013],\n",
      "        [ 0.9277,  0.3734,  0.5529],\n",
      "        [ 0.9466,  0.3223, -0.0761],\n",
      "        [-0.8658, -0.5003, -0.7582],\n",
      "        [-0.9185,  0.3953,  0.9627],\n",
      "        [-0.7720, -0.6357, -0.7106],\n",
      "        [ 0.6958, -0.7183,  0.5680],\n",
      "        [-0.7593,  0.6508, -0.4263],\n",
      "        [ 0.9118, -0.4106,  0.6329],\n",
      "        [-0.9122, -0.4097, -0.9279]])\n",
      "tensor([[ 0.7515],\n",
      "        [ 0.6436],\n",
      "        [-0.3729],\n",
      "        [-0.1504],\n",
      "        [ 0.1852],\n",
      "        [ 0.3112],\n",
      "        [-0.6996],\n",
      "        [-0.3884],\n",
      "        [-1.2042],\n",
      "        [-0.1945],\n",
      "        [-0.6525],\n",
      "        [-1.5050],\n",
      "        [-0.9077],\n",
      "        [ 1.4283],\n",
      "        [ 0.6604],\n",
      "        [-0.0487]])\n",
      "Normal(scale: torch.Size([16, 1]), loc: torch.Size([16, 1]))\n",
      "tensor([[0.0717],\n",
      "        [0.0144],\n",
      "        [0.0749],\n",
      "        [0.1450],\n",
      "        [0.1400],\n",
      "        [0.0267],\n",
      "        [0.0923],\n",
      "        [0.0233],\n",
      "        [0.0257],\n",
      "        [0.0921],\n",
      "        [0.0961],\n",
      "        [0.0923],\n",
      "        [0.1023],\n",
      "        [0.0682],\n",
      "        [0.0819],\n",
      "        [0.0868]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "temp = ActorCritic(envs.observation_space.shape[0],envs.action_space.shape[0],10).to(device)\n",
    "print(temp)\n",
    "temp_state = envs.reset()\n",
    "temp_state = torch.FloatTensor(temp_state).to(device)\n",
    "tm_dist, tm_val = temp(temp_state)\n",
    "print(temp_state)\n",
    "print(tm_dist.sample())\n",
    "print(tm_dist)\n",
    "print(tm_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "    \n",
    "def test_env(vis=False):\n",
    "    state = env.reset()\n",
    "    if vis: env.render()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        next_state, reward, done, _ = env.step(dist.sample().cpu().numpy()[0])\n",
    "        state = next_state\n",
    "        if vis: env.render()\n",
    "        total_reward += reward\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>GAE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gae(next_value, rewards, masks, values, gamma=0.99, tau=0.95):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Proximal Policy Optimization Algorithm</h1>\n",
    "<h2><a href=\"https://arxiv.org/abs/1707.06347\">Arxiv</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantage):\n",
    "    batch_size = states.size(0)\n",
    "    for _ in range(batch_size // mini_batch_size):\n",
    "        rand_ids = np.random.randint(0, batch_size, mini_batch_size)\n",
    "        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :]\n",
    "        \n",
    "        \n",
    "\n",
    "def ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, clip_param=0.2):\n",
    "    for _ in range(ppo_epochs):\n",
    "        for state, action, old_log_probs, return_, advantage \n",
    "        in ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantages):\n",
    "            dist, value = model(state)\n",
    "            entropy = dist.entropy().mean()\n",
    "            new_log_probs = dist.log_prob(action)\n",
    "\n",
    "            ratio = (new_log_probs - old_log_probs).exp()\n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * advantage\n",
    "\n",
    "            actor_loss  = - torch.min(surr1, surr2).mean()\n",
    "            critic_loss = (return_ - value).pow(2).mean()\n",
    "\n",
    "            loss = 0.5 * critic_loss + actor_loss - 0.001 * entropy\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomActorCritic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, n_latent_var, safety_dim):\n",
    "        super(ActorCritic, self).__init__()\n",
    "\n",
    "\n",
    "        layers_shared_actor = []\n",
    "        layers_safety_actor = []\n",
    "        layers_control_actor = []\n",
    "\n",
    "        layers_shared_critic = []\n",
    "        layers_safety_critic = []\n",
    "        layers_control_critic = []\n",
    "        \n",
    "\n",
    "        in_dim = state_dim\n",
    "        out_dim = n_latent_var\n",
    "\n",
    "        # shared part\n",
    "        for i in range(Num_Hidden_Shared):\n",
    "            layers_shared_actor.append(nn.Linear(in_dim, out_dim))\n",
    "            layers_shared_actor.append(nn.Tanh())\n",
    "            in_dim = out_dim\n",
    "\n",
    "        # safety head\n",
    "        for i in range(Num_Hidden_Safety):\n",
    "            layers_safety_actor.append(nn.Linear(in_dim, out_dim))\n",
    "            layers_safety_actor.append(nn.Tanh())\n",
    "\n",
    "        # action head\n",
    "        for i in range(Num_Hidden_Action):\n",
    "            layers_control_actor.append(nn.Linear(in_dim, out_dim))\n",
    "            layers_control_actor.append(nn.Tanh())\n",
    "\n",
    "        self.base_actor = nn.Sequential(*layers_shared_actor)\n",
    "\n",
    "        self.safety_layer_actor = nn.Sequential(*layers_safety_actor,\n",
    "                                    nn.Linear(out_dim, safety_dim)\n",
    "                                    )\n",
    "        \n",
    "        self.control_layer_actor = nn.Sequential(*layers_control_actor,\n",
    "                                    nn.Linear(out_dim, action_dim)\n",
    "                                    )\n",
    "\n",
    "\n",
    "        in_dim = state_dim\n",
    "        out_dim = n_latent_var\n",
    "\n",
    "        # shared part\n",
    "        for i in range(Num_Hidden_Shared):\n",
    "            layers_shared_critic.append(nn.Linear(in_dim, out_dim))\n",
    "            layers_shared_critic.append(nn.Tanh())\n",
    "            in_dim = out_dim\n",
    "\n",
    "        # safety head\n",
    "        for i in range(Num_Hidden_Safety):\n",
    "            layers_safety_critic.append(nn.Linear(in_dim, out_dim))\n",
    "            layers_safety_critic.append(nn.Tanh())\n",
    "\n",
    "        # action head\n",
    "        for i in range(Num_Hidden_Action):\n",
    "            layers_control_critic.append(nn.Linear(in_dim, out_dim))\n",
    "            layers_control_critic.append(nn.Tanh())\n",
    "\n",
    "        self.base_critic = nn.Sequential(*layers_shared_critic)\n",
    "\n",
    "        self.safety_layer_critic = nn.Sequential(*layers_safety_critic,\n",
    "                                    nn.Linear(out_dim, 1)\n",
    "                                    )\n",
    "        \n",
    "        self.action_layer_critic = nn.Sequential(*layers_control_critic,\n",
    "                                    nn.Linear(out_dim, 1)\n",
    "                                    )\n",
    "\n",
    "        \n",
    "    def forward(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def act(self, state, memory):\n",
    "        state = torch.from_numpy(state).float().to(device) \n",
    "        mu1 = self.control_layer_actor(self.base_actor(state)) # mu1\n",
    "        mu2 = self.safety_layer_actor(self.base_actor(state)) # mu2\n",
    "        \n",
    "        std1   = self.log_std.exp().expand_as(mu1)\n",
    "        dist1  = Normal(mu1, std1)\n",
    "\n",
    "        std2   = self.log_std.exp().expand_as(mu2)\n",
    "        dist2  = Normal(mu1, std2)\n",
    "\n",
    "        return dist1, dist2\n",
    "        \n",
    "        # memory.states.append(state)\n",
    "        # memory.actions.append(action)\n",
    "        \n",
    "#         return action.item(), safety.item()\n",
    "    \n",
    "    def evaluate(self, state, action):\n",
    "        # action_probs = self.action_layer(state)\n",
    "        # dist = Categorical(action_probs)\n",
    "        \n",
    "        # action_logprobs = dist.log_prob(action)\n",
    "        # dist_entropy = dist.entropy()\n",
    "        \n",
    "        control_state_value = self.control_layer_critic(self.base_critic(state))\n",
    "        safety_state_value = self.safety_layer_critic(self.base_critic(state))\n",
    "\n",
    "        # return action_logprobs, torch.squeeze(state_value), dist_entropy\n",
    "        return control_state_value, safety_state_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We need to update the weights of safety side similar to control side. (by symmetry)\n",
    "We just need to get the same inputs that are required to calculate the losses from the safety part as well\n",
    "\n",
    "Just assume we have two networks and we want to do ppo on both of them. So calculate loss and do weighted addition\n",
    "and back propagate\n",
    "\n",
    "Equivalents needed:\n",
    "    actions : safety\n",
    "    log_probs : safety_log_probs\n",
    "    returns : safety_returns\n",
    "    advantages : safety_advantages\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "CTRL_W = 0.7\n",
    "SFTY_W = 0.3\n",
    "\n",
    "\n",
    "# def ppo_iter_new(mini_batch_size, states, actions, log_probs, returns, advantage):\n",
    "def ppo_iter_new(mini_batch_size, states, controls, safetys, log_probs_c, log_probs_s, returns_c, returns_s, \\\n",
    "                 advantages_c, advantages_s):\n",
    "    batch_size = states.size(0)\n",
    "    for _ in range(batch_size // mini_batch_size):\n",
    "        rand_ids = np.random.randint(0, batch_size, mini_batch_size)\n",
    "#         yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :]\n",
    "        yield states[rand_ids, :], controls[rand_ids, :], safetys[rand_ids, :], log_probs_c[rand_ids, :], \\\n",
    "    log_probs_s[rand_ids, :], returns_c[rand_ids, :], returns_s[rand_ids, :], advantages_c[rand_ids, :], advantages_s[rand_ids, :]\n",
    "        \n",
    "        \n",
    "\n",
    "# def ppo_update_new(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, clip_param=0.2):\n",
    "def ppo_update_new(ppo_epochs, mini_batch_size, states, controls, safetys, log_probs_c, log_probs_s \\\n",
    "                   , returns_c, returns_s, advantages_c, advantages_s, clip_param=0.2):\n",
    "    for _ in range(ppo_epochs):\n",
    "        \n",
    "#         for state, action, old_log_probs, return_, advantage in ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantages):\n",
    "        for state, control, safety, old_log_probs_c, old_log_probs_s, return_c, return_s, advantage_c, advantage_s \\\n",
    "                        in ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantages):\n",
    "\n",
    "#             dist, value = model(state)\n",
    "            dist_c, dist_s = model.act(state)\n",
    "            value_c, value_s  = model.evaluate(state)\n",
    "\n",
    "#             entropy = dist.entropy().mean()\n",
    "            entropy_c = dist_c.entropy().mean()\n",
    "            entropy_s = dist_s.entropy().mean()\n",
    "        \n",
    "#             new_log_probs = dist.log_prob(action)                \n",
    "            new_log_probs_c = dist_c.log_prob(control)\n",
    "            new_log_probs_s = dist_s.log_prob(safety)\n",
    "        \n",
    "        \n",
    "#             ratio = (new_log_probs - old_log_probs).exp()\n",
    "            ratio_c = (new_log_probs_c - old_log_probs_c).exp()\n",
    "            ratio_s = (new_log_probs_s - old_log_probs_s).exp()\n",
    "    \n",
    "#             surr1 = ratio * advantage\n",
    "            surr1_c = ratio_c * advantage_c\n",
    "            surr1_s = ratio_s * advantage_s\n",
    "    \n",
    "#             surr2 = torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * advantage\n",
    "            surr2_c = torch.clamp(ratio_c, 1.0 - clip_param, 1.0 + clip_param) * advantage_c\n",
    "            surr2_s = torch.clamp(ratio_s, 1.0 - clip_param, 1.0 + clip_param) * advantage_s\n",
    "    \n",
    "    \n",
    "#             actor_loss  = - torch.min(surr1, surr2).mean()\n",
    "            actor_loss_c = - torch.min(surr1_c, surr2_c).mean()\n",
    "            actor_loss_s = - torch.min(surr1_s, surr2_s).mean()\n",
    "    \n",
    "#             critic_loss = (return_ - value).pow(2).mean()\n",
    "            critic_loss_c = (return_c - value_c).pow(2).mean()\n",
    "            critic_loss_s = (return_s - value_s).pow(2).mean()\n",
    "\n",
    "\n",
    "#             loss = 0.5 * critic_loss + actor_loss - 0.001 * entropy\n",
    "            loss_c = 0.5 * critic_loss_c + actor_loss_c - 0.001 * entropy_c\n",
    "            loss_s = 0.5 * critic_loss_s + actor_loss_s - 0.001 * entropy_s\n",
    "    \n",
    "            loss = CTRL_W*loss_c + SFTY_W*loss_s\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs  = envs.observation_space.shape[0]\n",
    "num_outputs = envs.action_space.shape[0]\n",
    "\n",
    "#Hyper params:\n",
    "hidden_size      = 256\n",
    "lr               = 3e-4\n",
    "num_steps        = 20\n",
    "mini_batch_size  = 5\n",
    "ppo_epochs       = 4\n",
    "threshold_reward = -200\n",
    "\n",
    "model = ActorCritic(num_inputs, num_outputs, hidden_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frames = 15000\n",
    "frame_idx  = 0\n",
    "test_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = envs.reset()\n",
    "early_stop = False\n",
    "\n",
    "while frame_idx < max_frames and not early_stop:\n",
    "\n",
    "    log_probs = []\n",
    "    values    = []\n",
    "    states    = []\n",
    "    actions   = []\n",
    "    rewards   = []\n",
    "    masks     = []\n",
    "    entropy = 0\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        dist, value = model(state)\n",
    "\n",
    "        action = dist.sample()\n",
    "        next_state, reward, done, _ = envs.step(action.cpu().numpy())\n",
    "\n",
    "        log_prob = dist.log_prob(action)\n",
    "        entropy += dist.entropy().mean()\n",
    "        \n",
    "        log_probs.append(log_prob)\n",
    "        values.append(value)\n",
    "        rewards.append(torch.FloatTensor(reward).unsqueeze(1).to(device))\n",
    "        masks.append(torch.FloatTensor(1 - done).unsqueeze(1).to(device))\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        \n",
    "        state = next_state\n",
    "        frame_idx += 1\n",
    "        \n",
    "        if frame_idx % 1000 == 0:\n",
    "            test_reward = np.mean([test_env() for _ in range(10)])\n",
    "            test_rewards.append(test_reward)\n",
    "            plot(frame_idx, test_rewards)\n",
    "            if test_reward > threshold_reward: early_stop = True\n",
    "            \n",
    "\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    _, next_value = model(next_state)\n",
    "    returns = compute_gae(next_value, rewards, masks, values)\n",
    "\n",
    "    returns   = torch.cat(returns).detach()\n",
    "    log_probs = torch.cat(log_probs).detach()\n",
    "    values    = torch.cat(values).detach()\n",
    "    states    = torch.cat(states)\n",
    "    actions   = torch.cat(actions)\n",
    "    advantage = returns - values\n",
    "    \n",
    "    ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Saving trajectories for GAIL</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0 reward: -9.379095587032706\n",
      "episode: 1 reward: -9.650909347140873\n",
      "episode: 2 reward: -9.239020824482216\n",
      "episode: 3 reward: -9.08145820218229\n",
      "episode: 4 reward: -9.754058352832722\n",
      "episode: 5 reward: -8.787385990259725\n",
      "episode: 6 reward: -9.960827471049809\n",
      "episode: 7 reward: -9.383103664844352\n",
      "episode: 8 reward: -9.21930627510877\n",
      "episode: 9 reward: -9.392032602524893\n",
      "episode: 10 reward: -8.971582591460887\n",
      "episode: 11 reward: -9.117912064597304\n",
      "episode: 12 reward: -8.78152662300433\n",
      "episode: 13 reward: -9.890438673703049\n",
      "episode: 14 reward: -9.54285322963302\n",
      "episode: 15 reward: -9.41677616518869\n",
      "episode: 16 reward: -8.978002589039926\n",
      "episode: 17 reward: -9.786747572291842\n",
      "episode: 18 reward: -9.040926985899137\n",
      "episode: 19 reward: -9.48965082152691\n",
      "episode: 20 reward: -9.508202258492254\n",
      "episode: 21 reward: -9.057053059323461\n",
      "episode: 22 reward: -9.819452759432647\n",
      "episode: 23 reward: -9.805622747689124\n",
      "episode: 24 reward: -9.254766119386941\n",
      "episode: 25 reward: -9.474071662816893\n",
      "episode: 26 reward: -8.992316209890427\n",
      "episode: 27 reward: -10.282954007778248\n",
      "episode: 28 reward: -9.011238642006349\n",
      "episode: 29 reward: -8.972805993176761\n",
      "episode: 30 reward: -9.623902668422575\n",
      "episode: 31 reward: -9.859476343867318\n",
      "episode: 32 reward: -8.919275223025556\n",
      "episode: 33 reward: -9.240241611169468\n",
      "episode: 34 reward: -9.361412326843997\n",
      "episode: 35 reward: -9.320278867882282\n",
      "episode: 36 reward: -9.652660506034406\n",
      "episode: 37 reward: -9.212631603521288\n",
      "episode: 38 reward: -9.224924478397542\n",
      "episode: 39 reward: -9.678577056498254\n",
      "episode: 40 reward: -9.472000122268634\n",
      "episode: 41 reward: -8.984706614087257\n",
      "episode: 42 reward: -9.395115387380619\n",
      "episode: 43 reward: -9.37510810653667\n",
      "episode: 44 reward: -9.655783567346932\n",
      "episode: 45 reward: -10.021133317766772\n",
      "episode: 46 reward: -10.339772991224601\n",
      "episode: 47 reward: -9.28109806473477\n",
      "episode: 48 reward: -9.290320988579284\n",
      "episode: 49 reward: -9.582074860599231\n",
      "episode: 50 reward: -9.24944545068257\n",
      "\n",
      "(50949, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import count\n",
    "\n",
    "max_expert_num = 50000\n",
    "num_steps = 0\n",
    "expert_traj = []\n",
    "\n",
    "for i_episode in count():\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        action = dist.sample().cpu().numpy()[0]\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        expert_traj.append(np.hstack([state, action]))\n",
    "        num_steps += 1\n",
    "    \n",
    "    print(\"episode:\", i_episode, \"reward:\", total_reward)\n",
    "    \n",
    "    if num_steps >= max_expert_num:\n",
    "        break\n",
    "        \n",
    "expert_traj = np.stack(expert_traj)\n",
    "print()\n",
    "print(expert_traj.shape)\n",
    "print()\n",
    "np.save(\"expert_traj.npy\", expert_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
